
<!DOCTYPE html>

<html lang="es">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Machine learning, Deep Learning y NLP &#8212; Mi aprendizaje sobre NLP</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" />
    <link rel="next" title="Acercamientos a NLP" href="04-nlp.html" />
    <link rel="prev" title="¿Qué es el lenguaje?" href="02-lenguaje.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="es">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Mi aprendizaje sobre NLP</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Buscar este libro ..." aria-label="Buscar este libro ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../cover.html">
   Bienvenid@
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introducción a NLP
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01-intro.html">
   NLP en el mundo real
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02-lenguaje.html">
   ¿Qué es el lenguaje?
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Machine learning, Deep Learning y NLP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04-nlp.html">
   Acercamientos a NLP
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pipelines de procesamiento
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../02-pipeline/01-data-adquisition.html">
   Adquisición de datos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02-pipeline/02-text-extraction-cleanup.html">
   Extracción y limpieza de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02-pipeline/03-preprocesamiento.html">
   Pre-procesamiento
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02-pipeline/04-feature-engineering.html">
   Feature engineering y extracción de características
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02-pipeline/05-modeling-evaluation.html">
   Modelamiento y evaluación del pipeline
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Representaciones del texto
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03-representacion-texto/01-vector-space-models.html">
   Modelos de espacios vectoriales
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-representacion-texto/01z1-bag-of-words.html">
     Bag of Words
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03-representacion-texto/02-vectorization-approaches.html">
   Enfoques básicos de vectorización
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Navegación de palanca" aria-controls="site-navigation"
                title="Navegación de palanca" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Descarga esta pagina"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/chapters/01-introduccion/03-ml-dl-nlp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Descargar archivo fuente" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Imprimir en PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/rickiwasho/nlp-apuntes"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Repositorio de origen"><i
                    class="fab fa-github"></i>repositorio</button></a>
        <a class="issues-button"
            href="https://github.com/rickiwasho/nlp-apuntes/issues/new?title=Issue%20on%20page%20%2Fchapters/01-introduccion/03-ml-dl-nlp.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Abrir un problema"><i class="fas fa-lightbulb"></i>Tema abierto</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Modo de pantalla completa"
        title="Modo de pantalla completa"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/rickiwasho/nlp-apuntes/master?urlpath=tree/docs/chapters/01-introduccion/03-ml-dl-nlp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Lanzamiento Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contenido
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#enfoques-de-nlp">
   Enfoques de NLP
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basado-en-heuristicas">
     1. basado en heurísticas
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basado-en-machine-learning">
     2. basado en Machine Learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#naive-bayes">
       - Naive Bayes
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#support-vector-machine-svm">
       - Support Vector Machine (SVM)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hidden-markov-model-hmm">
       - Hidden Márkov Model (HMM)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#conditional-random-fields-crf">
       - Conditional Random Fields (CRF)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basado-en-deep-learning">
     3. basado en Deep Learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#recurrent-neural-networks-rnn">
       - Recurrent Neural Networks (RNN)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#long-short-term-memory-lstm">
       - Long short-term memory (LSTM)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#convolutional-neural-networks">
       - Convolutional neural networks
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transformers">
       - Transformers
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoders">
       - Autoencoders
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Machine learning, Deep Learning y NLP</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contenido </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#enfoques-de-nlp">
   Enfoques de NLP
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basado-en-heuristicas">
     1. basado en heurísticas
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basado-en-machine-learning">
     2. basado en Machine Learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#naive-bayes">
       - Naive Bayes
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#support-vector-machine-svm">
       - Support Vector Machine (SVM)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hidden-markov-model-hmm">
       - Hidden Márkov Model (HMM)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#conditional-random-fields-crf">
       - Conditional Random Fields (CRF)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basado-en-deep-learning">
     3. basado en Deep Learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#recurrent-neural-networks-rnn">
       - Recurrent Neural Networks (RNN)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#long-short-term-memory-lstm">
       - Long short-term memory (LSTM)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#convolutional-neural-networks">
       - Convolutional neural networks
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transformers">
       - Transformers
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoders">
       - Autoencoders
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="machine-learning-deep-learning-y-nlp">
<h1>Machine learning, Deep Learning y NLP<a class="headerlink" href="#machine-learning-deep-learning-y-nlp" title="Enlazar permanentemente con este título">¶</a></h1>
<p>La <strong>inteligencia artificial</strong> (AI) es una rama de las ciencias de la computación cuyo objetivo es construir sistemas que puedan desarrollar tareas que requieran de la inteligencia humana.</p>
<p><strong>Machine learning</strong> (ML o aprendizaje de máquina) es una rama de la inteligencia artificial cuyo objetivo es desarrollar algoritmos que pueden aprender a desarrollar tareas de forma automática, basándose en un gran número de ejemplos.</p>
<p><strong>Deep Learning</strong> (DL o aprendizaje profundo) es una rama de machine learning basada en arquitecturas de redes neuronales artificiales</p>
<p>NLP, ML y DL pueden traslaparse, sin embargo, son áreas de estudio diferentes.<br />
Al igual que en la inteligencia artificial, los primeros avances de NLP eran basados en reglas y heurísticas. Luego, con el paso de los años y los grandes avances en ML y DL, NLP fue adquiriendo parte de sus técnicas, modelos y arquitecturas.</p>
<a class="reference internal image-reference" href="https://miro.medium.com/max/1400/1*TURvrYWSTRQLGF6sJ025gw.png"><img alt="https://miro.medium.com/max/1400/1*TURvrYWSTRQLGF6sJ025gw.png" src="https://miro.medium.com/max/1400/1*TURvrYWSTRQLGF6sJ025gw.png" style="width: 600px;" /></a>
<p>El objetivo del machine learning es “aprender” a desarrollar tareas basándose en ejemplos (llamados “datos de entrenamiento”) sin instrucciones explícitas. Esto típicamente se realiza creando una representación numérica de los datos de entrenamiento y usando dicha representación para aprender los patrones implícitos.</p>
<p>Los algoritmos de machine learning se pueden agrupar en tres paradigmas: <em>aprendizaje supervisado, aprendizaje no supervisado y aprendizaje por reforzamiento.</em></p>
<ul class="simple">
<li><p>En el <strong>aprendizaje supervisado</strong>, el objetivo es aprender la función de mapeo de entrada a salida dada una gran cantidad de ejemplos en forma de pares de entrada-salida. Los pares de entrada-salida se conocen como <em>datos de entrenamiento</em> y las salidas se conocen específicamente como <em>etiquetas</em>. Un ejemplo de un problema de aprendizaje supervisado relacionado con el lenguaje es aprender a clasificar los correos electrónicos como spam o no spam dados miles de ejemplos en ambas categorías. Este es un escenario común en la PNL.</p></li>
<li><p>El <strong>aprendizaje no supervisado</strong> se refiere a un conjunto de métodos de machine learning que tienen como objetivo encontrar patrones ocultos en los datos de entrada sin ninguna salida de referencia. Es decir, en contraste con el aprendizaje supervisado, el aprendizaje no supervisado funciona con grandes colecciones de datos no etiquetados. En NLP, un ejemplo de tal tarea es identificar temas latentes en una gran colección de datos textuales sin ningún conocimiento de estos temas. Esto se conoce como <em>topic modeling</em> (modelado de temas).</p></li>
<li><p>El <strong>aprendizaje por reforzamiento</strong> se ocupa de métodos para aprender tareas a través de prueba y error. Se caracteriza por la ausencia de datos etiquetados o no-etiquetados en grandes cantidades. El aprendizaje se realiza en un entorno autónomo y mejora a través de la retroalimentación (recompensa y castigo) facilitada por el entorno. Esta forma de aprendizaje no es común en la NLP (todavía). Es más común en aplicaciones como juegos (go, ajedrez, etc),  en el diseño de vehículos autónomos y en la robótica.</p></li>
</ul>
<section id="enfoques-de-nlp">
<h2>Enfoques de NLP<a class="headerlink" href="#enfoques-de-nlp" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Los diferentes acercamientos usados para resolver problemas de NLP comúnmente caen en tres categorías: heurísticas, machine learning y deep learning.</p>
<section id="basado-en-heuristicas">
<h3>1. basado en heurísticas<a class="headerlink" href="#basado-en-heuristicas" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Similar a los primeros sistemas de inteligencia artificial, los primeros intentos para diseñar sistemas de NLP estuvieron basados en la construcción a mano de reglas para resolver problemas del lenguaje. Esto requeria que los desarrolladores tuvieran cierta expertiz en el dominio para formular reglas que pudieran ser incorporadas en un programa. Estos sistemas requerian recursos como diccionarios y diccionarios de sinónimos y antónimos (tesauros), típicamente compilados y digitalizados a través de ciertos periodos de tiempo. Un ejemplo de diseñar reglas para resolver un problema de NLP usando recursos es el “lexicon-based sentiment analysis” (o análisis de sentimientos basado en léxico). Utiliza contadores de palabras positivas y negativas en el texto para deducir el sentimiento del texto.</p>
<p>Las <strong>expresiones regulares</strong> (Regex) son una buena herramienta para el análisis de textos y para la construcción de sistemas basados en reglas. Una expresión regular es un conjunto de caracteres o un patrón que se usa para encontrar substrings en el texto. Además son usadas para matches o coincidencias determinísticas -vale decir, es una coincidencia o no lo es. Las expresiones regulares probabilísticas son una rama secundaria que aborda esta limitanción al incluir una probabilidad de coincidencia.</p>
<p>La <strong>gramática de libre contexto</strong> (Context-free grammar o CFG) es un tipo de gramática formal que es usado para modelar lenguajes naturales. CFG fue inventada por <a class="reference external" href="https://en.wikipedia.org/wiki/Noam_Chomsky"><em>Noam Chomsky</em></a> y permite capturar información más compleja y jerárquica, en situaciones donde posiblemente las expresiones regulares serían una herramienta incompatible.</p>
<p>Las reglas y heurísticas juegan un rol importante en el ciclo de vida de los proyectos de NLP. Son una excelente forma de empezar a construir las primeras versiones de nuestros sistemas. Con tan solo un par de reglas y heurísticas puedes construir un modelo simple que te permitirá entender de mejor forma el problema.</p>
</section>
<section id="basado-en-machine-learning">
<h3>2. basado en Machine Learning<a class="headerlink" href="#basado-en-machine-learning" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Las técnicas de machine learning, como los métodos de clasificación y regresión, se utilizan mucho para diversas tareas de NLP. Como ejemplo, es posible clasificar un abanico de noticias en distintas categorias como economía, deportes o política. Por otro lado, las técnicas de regresión pueden entregarnos valores estimados a partir de un análisis de sentimientos de un activo en redes sociales.</p>
<p>Cualquier acercamiento de machine learning a NLP, supervisado o no supervisado, puede ser descrito consistentemente en tres pasos comunes:</p>
<ol class="simple">
<li><p>extraer características del texto.</p></li>
<li><p>usar la representacipon de características para que el modelo pueda aprender</p></li>
<li><p>evaluar y mejorar el modelo.</p></li>
</ol>
<section id="naive-bayes">
<h4>- Naive Bayes<a class="headerlink" href="#naive-bayes" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Naive Bayes es un algoritmo clásico para las tareas de clasificación que principalmente se basa en el <a class="reference external" href="https://en.wikipedia.org/wiki/Bayes%27_theorem"><em>teorema de bayes</em></a>. Usando el teorema de bayes se calcula la probabilidad de observar una categoría dado cierto input y las características de los datos. Una particularidad de este algoritmo es que asume que cada característica es independiente de las demás categorías. Por ejemplo, un modelo naive bayes clasificador de noticias puede representar el texto de forma numérica usando un contador de palabras clave por clase, palabras que son específicas para la clase deportes, política, arte, etc. y que están presentes en el texto. Se asume que estos contadores de palabras no están correlacionados con las demás categorías, y aunque esta asumpción es bastante fuerte, en algunos casos (poco probables) puede arrojar falsos positivos.</p>
<a class="reference internal image-reference" href="https://miro.medium.com/max/1200/0*Z3nK2E6TghNWzZGz.png"><img alt="https://miro.medium.com/max/1200/0*Z3nK2E6TghNWzZGz.png" src="https://miro.medium.com/max/1200/0*Z3nK2E6TghNWzZGz.png" style="width: 400px;" /></a>
</section>
<section id="support-vector-machine-svm">
<h4>- Support Vector Machine (SVM)<a class="headerlink" href="#support-vector-machine-svm" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Support Vector Machine es otro algoritmo de clasificación popular. El objetivo en cualquier técnica de clasificación es aprender los límites que actúan como separadores entre las distintas clases o categorías de texto (por ejemplo, política versus deportes, en nuestro ejemplo de clasificación de noticias). Estos límites de decisión pueden ser lineales o no lineales. SVM puede aprender límites de decisión lineales o no lineales para separar los datos pertenecientes a las distintas clases.</p>
<p>Una SVM puede aprender un límite de decisión óptimo para que la distancia entre los puntos de las clases sea máxima. La mayor fortaleza de las SVM es su solidez a la variación y el ruido en los datos. Una debilidad importante es el tiempo que se tarda en entrenar y la incapacidad de escalar cuando hay grandes cantidades de datos de entrenamiento.</p>
<a class="reference internal image-reference" href="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0111.png"><img alt="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0111.png" src="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0111.png" style="width: 300px;" /></a>
</section>
<section id="hidden-markov-model-hmm">
<h4>- Hidden Márkov Model (HMM)<a class="headerlink" href="#hidden-markov-model-hmm" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Hidden Markov Model (modelo oculto de Márkov o HMM) es un modelo estadístico que asume que hay un subyacente e inobservable proceso con estados ocultos que generan los datos, donde sólo se pueden observar los datos cuando son generados. Un HMM entonces intenta modelar los estados ocultos desde estos datos.</p>
<p>Por ejemplo, considera la tarea de reconocer el tipo de entidad de cierta palabra en una oración, ya sea verbo, pronombre, adjetivo, etc., esto se conoce como <em>Part-of-speech (POS) tagging</em>. HMMs es utilizado para reconocer estos tags en las palabras porque sabemos que detrás de cada palabra hay una gramática subyacente que está escondida y le da la lógica al texto. Los estados escondidos en este caso definen la estructura de la oración seguidos de la gramática del lenguaje, pero nosotros como observadores sólo somos capaces de ver las palabras que son gobernadas por estos estados latentes.<br />
Además de esto, HMM también hace la suposición de Márkov, lo que significa que cada estado oculto depende de el o los estados anteriores. El lenguaje humano es secuencial en naturaleza, y una palabra actual en una oración depende de lo que haya ocurrido antes de ella. Por esto, HMMs con estas dos asumpciones son una poderosa herramienta para modelar datos textuales.</p>
<a class="reference internal image-reference" href="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0112.png"><img alt="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0112.png" src="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0112.png" style="width: 500px;" /></a>
<p>La imagen muestra una HMM que aprende los tags del POS. En este caso, JJ(adjetive) y NN (noun) son estados ocultos, mientras que “natural language processing (nlp) …” son directamente observables.</p>
</section>
<section id="conditional-random-fields-crf">
<h4>- Conditional Random Fields (CRF)<a class="headerlink" href="#conditional-random-fields-crf" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Conditional random field (campo aleatorio condicional o CRF) es otro algorimo usado para datos secuenciales. Conceptualmente, CRF realiza una tarea de clasificación en cada elemento de la secuencia. Imagine el mismo ejemplo de POS tagging, donde un CRF puede etiquetar palabra por palabra clasificándolas en una clase del grupo de todos los tags de POS.</p>
<p>Dado que tiene en cuenta el input secuencial y el contexto de los tags, se vuelve más expresivo que los métodos de clasificación habituales y, en general, funciona mejor. Los CRF superan a los HMM en tareas como el POS tagging, que se basan en la naturaleza secuencial del lenguaje.</p>
</section>
</section>
<section id="basado-en-deep-learning">
<h3>3. basado en Deep Learning<a class="headerlink" href="#basado-en-deep-learning" title="Enlazar permanentemente con este título">¶</a></h3>
<p>En los últimos años, se ha visto un surgimiento incrementado en el uso de redes neuronales que tratan con datos complejos y no estructurados. El lenguaje es inherentemente complejo y no estructurado. De esta forma, es necesario de modelos con mejores representaciones y capacidad de aprendizaje para entender y resolver tareas del lenguaje.</p>
<p>Las siguientes son las arquitecturas de redes neuronales profundas que se han vuelto el status quo en NLP.</p>
<section id="recurrent-neural-networks-rnn">
<h4>- Recurrent Neural Networks (RNN)<a class="headerlink" href="#recurrent-neural-networks-rnn" title="Enlazar permanentemente con este título">¶</a></h4>
<p>El lenguaje es inherentemente secuencial. Una oración en cualquier lenguaje fluye desde una dirección a otra (por ejemplo, en inglés o español se lee desde izquierda a derecha). Por lo tanto, un modelo que pueda leer progresivamente un input de texto desde un extremo a otro puede ser muy útil para el entendimiento del lenguaje. Las redes neuronales recurrentes (RNNs) están especialmente diseñadas para mantener este procesamiento secuencial y aprendizaje en mente. RNNs tienen unidades neuronales que son capaces de recordar lo que han procesado hasta ahora. Esta memoria es temporal, y la información es almacenada y actualizada con cada paso mientras RNN lee la siguiente palabra del input.</p>
<p>La siguiente imagen ilustra una RNN desenrollada y como esta sigue la pista de sus inputs en distintos momentos.</p>
<a class="reference internal image-reference" href="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0113.png"><img alt="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0113.png" src="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0113.png" style="width: 500px;" /></a>
<p>Las RNN son muy poderosas y trabajan muy bien resolviendo problemas de NLP, como la clasificación de texto, reconocimiento de entidades nombradas (<em>named entity recognition</em> o NER), traducción automática, etc. También es posible generar texto con RNNs donde el objetivo es leer el texto que precede y predecir la palabra siguiente o el siguiente caracter.</p>
</section>
<section id="long-short-term-memory-lstm">
<h4>- Long short-term memory (LSTM)<a class="headerlink" href="#long-short-term-memory-lstm" title="Enlazar permanentemente con este título">¶</a></h4>
<p>A pesar de su capacidad y versatilidad, RNNs sufren el problema de la “pérdida de memoria”, estas no pueden recordad largos contextos, y por lo tanto, no son eficientes cuando el input es grande, situación que típicamente es el caso con los inputs de texto. Long short-term memory networks (LSTMs), un tipo de RNN, fueron inventadas para mitigar este defecto de las RNNs.</p>
<p>LSTM sortea este problema dejando de lado el contexto irrelevante y recordando solo la parte del contexto que se necesita para resolver la tarea en cuestión. Esto alivia la carga de recordar un contexto muy largo en una representación vectorial. Los LSTM han reemplazado a los RNN en la mayoría de las aplicaciones debido a esta solución.</p>
<p>La siguiente figura ilustra la arquitectura de una sola celda LSTM</p>
<a class="reference internal image-reference" href="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0114.png"><img alt="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0114.png" src="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0114.png" style="width: 500px;" /></a>
</section>
<section id="convolutional-neural-networks">
<h4>- Convolutional neural networks<a class="headerlink" href="#convolutional-neural-networks" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Las redes neuronales convolucionales (CNNs) son bastante populares y altamente usadas en tareas de visión computacional como clasificación de imágenes, reconocimiento de video, etc. Además, las CNNs hay sido bastante exitosas en NLP, especialmente en las tareas de clasificación de texto. Uno puede reemplazar cada palabra de una oración en una representación vectorizada de la misma, donde todos y cada uno los vectores son del mismo tamaño (<em>Word Embeddings</em>).</p>
<p>Además, estos vectores pueden ser apilados uno sobre otro para formar una matriz o un arreglo en 2D de dimensiones <em>n</em> x <em>d</em>, donde <em>n</em> es el número de palabras en una oración y <em>d</em> es el tamaño de la vectorización de las palabras. Esta matriz puede ser tratada de forma similar a una imagen y puede ser modelada por una CNN.</p>
<p><strong>La ventaja principal que tienen las CNNs es su capacidad de mirar un grupo de palabras contiguas usando una ventana de contexto.</strong> Por ejemplo: se está haciendo un análisis de sentimiento y se obtiene la siguiente oración: <em>“I like this movie very much!”</em>. Para dar sentido a esta oración, hay que analizar cada una de las palabras y diferentes conjuntos que se forman a partir de las palabras contiguas. Las CNNs pueden hacer exactamente esto por definición de su arquitectura.</p>
<p><a class="reference internal" href="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0115.png"><img alt="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0115.png" src="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0115.png" style="width: 500px;" /></a></p>
<p>Como se muestra en la imagen, CNN utiliza una colección de capas de convolución y agrupación (<em>pooling</em>) para lograr esta representación condensada del texto, que luego se alimenta como entrada a una capa completamente conectada para aprender algunas tareas de NLP como la clasificación de texto.</p>
</section>
<section id="transformers">
<h4>- Transformers<a class="headerlink" href="#transformers" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Los Transformers son la última gran innovación en NLP. Los modelos de transformers</p>
<p><a class="reference internal" href="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0116.png"><img alt="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0116.png" src="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0116.png" style="width: 500px;" /></a>
<a class="reference internal" href="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0117.png"><img alt="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0117.png" src="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0117.png" style="width: 500px;" /></a></p>
</section>
<section id="autoencoders">
<h4>- Autoencoders<a class="headerlink" href="#autoencoders" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference internal" href="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0118.png"><img alt="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0118.png" src="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0118.png" style="width: 500px;" /></a></p>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters/01-introduccion"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="02-lenguaje.html" title="anterior página">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">anterior</p>
            <p class="prev-next-title">¿Qué es el lenguaje?</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="04-nlp.html" title="siguiente página">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">siguiente</p>
        <p class="prev-next-title">Acercamientos a NLP</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      Por Ricardo Coronado Mera<br/>
    
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>