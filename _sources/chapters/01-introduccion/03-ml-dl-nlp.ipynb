{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fbb8e43",
   "metadata": {},
   "source": [
    "# Machine learning, Deep Learning y NLP\n",
    "\n",
    "La **inteligencia artificial** (AI) es una rama de las ciencias de la computación cuyo objetivo es construir sistemas que puedan desarrollar tareas que requieran de la inteligencia humana.\n",
    "\n",
    "**Machine learning** (ML o aprendizaje de máquina) es una rama de la inteligencia artificial cuyo objetivo es desarrollar algoritmos que pueden aprender a desarrollar tareas de forma automática, basándose en un gran número de ejemplos.\n",
    "\n",
    "**Deep Learning** (DL o aprendizaje profundo) es una rama de machine learning basada en arquitecturas de redes neuronales artificiales \n",
    "\n",
    "NLP, ML y DL pueden traslaparse, sin embargo, son áreas de estudio diferentes.   \n",
    "Al igual que en la inteligencia artificial, los primeros avances de NLP eran basados en reglas y heurísticas. Luego, con el paso de los años y los grandes avances en ML y DL, NLP fue adquiriendo parte de sus técnicas, modelos y arquitecturas.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*TURvrYWSTRQLGF6sJ025gw.png\" width=\"600\"/>\n",
    "\n",
    "\n",
    "El objetivo del machine learning es \"aprender\" a desarrollar tareas basándose en ejemplos (llamados \"datos de entrenamiento\") sin instrucciones explícitas. Esto típicamente se realiza creando una representación numérica de los datos de entrenamiento y usando dicha representación para aprender los patrones implícitos.\n",
    "\n",
    "Los algoritmos de machine learning se pueden agrupar en tres paradigmas: _aprendizaje supervisado, aprendizaje no supervisado y aprendizaje por reforzamiento._\n",
    "\n",
    "- En el **aprendizaje supervisado**, el objetivo es aprender la función de mapeo de entrada a salida dada una gran cantidad de ejemplos en forma de pares de entrada-salida. Los pares de entrada-salida se conocen como _datos de entrenamiento_ y las salidas se conocen específicamente como _etiquetas_. Un ejemplo de un problema de aprendizaje supervisado relacionado con el lenguaje es aprender a clasificar los correos electrónicos como spam o no spam dados miles de ejemplos en ambas categorías. Este es un escenario común en la PNL.\n",
    "\n",
    "- El **aprendizaje no supervisado** se refiere a un conjunto de métodos de machine learning que tienen como objetivo encontrar patrones ocultos en los datos de entrada sin ninguna salida de referencia. Es decir, en contraste con el aprendizaje supervisado, el aprendizaje no supervisado funciona con grandes colecciones de datos no etiquetados. En NLP, un ejemplo de tal tarea es identificar temas latentes en una gran colección de datos textuales sin ningún conocimiento de estos temas. Esto se conoce como _topic modeling_ (modelado de temas).\n",
    "\n",
    "- El **aprendizaje por reforzamiento** se ocupa de métodos para aprender tareas a través de prueba y error. Se caracteriza por la ausencia de datos etiquetados o no-etiquetados en grandes cantidades. El aprendizaje se realiza en un entorno autónomo y mejora a través de la retroalimentación (recompensa y castigo) facilitada por el entorno. Esta forma de aprendizaje no es común en la NLP (todavía). Es más común en aplicaciones como juegos (go, ajedrez, etc),  en el diseño de vehículos autónomos y en la robótica.\n",
    "\n",
    "\n",
    "## Enfoques de NLP\n",
    "\n",
    "Los diferentes acercamientos usados para resolver problemas de NLP comúnmente caen en tres categorías: heurísticas, machine learning y deep learning.\n",
    "\n",
    "### 1. basado en heurísticas\n",
    "\n",
    "Similar a los primeros sistemas de inteligencia artificial, los primeros intentos para diseñar sistemas de NLP estuvieron basados en la construcción a mano de reglas para resolver problemas del lenguaje. Esto requeria que los desarrolladores tuvieran cierta expertiz en el dominio para formular reglas que pudieran ser incorporadas en un programa. Estos sistemas requerian recursos como diccionarios y diccionarios de sinónimos y antónimos (tesauros), típicamente compilados y digitalizados a través de ciertos periodos de tiempo. Un ejemplo de diseñar reglas para resolver un problema de NLP usando recursos es el \"lexicon-based sentiment analysis\" (o análisis de sentimientos basado en léxico). Utiliza contadores de palabras positivas y negativas en el texto para deducir el sentimiento del texto.\n",
    "\n",
    "Las **expresiones regulares** (Regex) son una buena herramienta para el análisis de textos y para la construcción de sistemas basados en reglas. Una expresión regular es un conjunto de caracteres o un patrón que se usa para encontrar substrings en el texto. Además son usadas para matches o coincidencias determinísticas -vale decir, es una coincidencia o no lo es. Las expresiones regulares probabilísticas son una rama secundaria que aborda esta limitanción al incluir una probabilidad de coincidencia.\n",
    "\n",
    "La **gramática de libre contexto** (Context-free grammar o CFG) es un tipo de gramática formal que es usado para modelar lenguajes naturales. CFG fue inventada por [_Noam Chomsky_](https://en.wikipedia.org/wiki/Noam_Chomsky) y permite capturar información más compleja y jerárquica, en situaciones donde posiblemente las expresiones regulares serían una herramienta incompatible.\n",
    "\n",
    "Las reglas y heurísticas juegan un rol importante en el ciclo de vida de los proyectos de NLP. Son una excelente forma de empezar a construir las primeras versiones de nuestros sistemas. Con tan solo un par de reglas y heurísticas puedes construir un modelo simple que te permitirá entender de mejor forma el problema.\n",
    "\n",
    "\n",
    "### 2. basado en Machine Learning \n",
    "\n",
    "Las técnicas de machine learning, como los métodos de clasificación y regresión, se utilizan mucho para diversas tareas de NLP. Como ejemplo, es posible clasificar un abanico de noticias en distintas categorias como economía, deportes o política. Por otro lado, las técnicas de regresión pueden entregarnos valores estimados a partir de un análisis de sentimientos de un activo en redes sociales.\n",
    "\n",
    "Cualquier acercamiento de machine learning a NLP, supervisado o no supervisado, puede ser descrito consistentemente en tres pasos comunes: \n",
    "\n",
    "1. extraer características del texto.\n",
    "2. usar la representacipon de características para que el modelo pueda aprender\n",
    "3. evaluar y mejorar el modelo. \n",
    "\n",
    "#### - Naive Bayes\n",
    "\n",
    "Naive Bayes es un algoritmo clásico para las tareas de clasificación que principalmente se basa en el [*teorema de bayes*](https://en.wikipedia.org/wiki/Bayes%27_theorem). Usando el teorema de bayes se calcula la probabilidad de observar una categoría dado cierto input y las características de los datos. Una particularidad de este algoritmo es que asume que cada característica es independiente de las demás categorías. Por ejemplo, un modelo naive bayes clasificador de noticias puede representar el texto de forma numérica usando un contador de palabras clave por clase, palabras que son específicas para la clase deportes, política, arte, etc. y que están presentes en el texto. Se asume que estos contadores de palabras no están correlacionados con las demás categorías, y aunque esta asumpción es bastante fuerte, en algunos casos (poco probables) puede arrojar falsos positivos.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1200/0*Z3nK2E6TghNWzZGz.png\" width=\"400\"/>\n",
    "\n",
    "#### - Support Vector Machine (SVM)\n",
    "\n",
    "Support Vector Machine es otro algoritmo de clasificación popular. El objetivo en cualquier técnica de clasificación es aprender los límites que actúan como separadores entre las distintas clases o categorías de texto (por ejemplo, política versus deportes, en nuestro ejemplo de clasificación de noticias). Estos límites de decisión pueden ser lineales o no lineales. SVM puede aprender límites de decisión lineales o no lineales para separar los datos pertenecientes a las distintas clases. \n",
    "\n",
    "Una SVM puede aprender un límite de decisión óptimo para que la distancia entre los puntos de las clases sea máxima. La mayor fortaleza de las SVM es su solidez a la variación y el ruido en los datos. Una debilidad importante es el tiempo que se tarda en entrenar y la incapacidad de escalar cuando hay grandes cantidades de datos de entrenamiento. \n",
    "\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0111.png\" width=\"300\"/>\n",
    "\n",
    "#### - Hidden Márkov Model (HMM)\n",
    "\n",
    "Hidden Markov Model (modelo oculto de Márkov o HMM) es un modelo estadístico que asume que hay un subyacente e inobservable proceso con estados ocultos que generan los datos, donde sólo se pueden observar los datos cuando son generados. Un HMM entonces intenta modelar los estados ocultos desde estos datos. \n",
    "\n",
    "Por ejemplo, considera la tarea de reconocer el tipo de entidad de cierta palabra en una oración, ya sea verbo, pronombre, adjetivo, etc., esto se conoce como _Part-of-speech (POS) tagging_. HMMs es utilizado para reconocer estos tags en las palabras porque sabemos que detrás de cada palabra hay una gramática subyacente que está escondida y le da la lógica al texto. Los estados escondidos en este caso definen la estructura de la oración seguidos de la gramática del lenguaje, pero nosotros como observadores sólo somos capaces de ver las palabras que son governadas por estos estados latentes.   \n",
    "Además de esto, HMM también hace la suposición de Márkov, lo que significa que cada estado oculto depende de el o los estados anteriores. El lenguaje humano es secuencial en naturaleza, y una palabra actual en una oración depende de lo que haya ocurrido antes de ella. Por esto, HMMs con estas dos asumpciones son una poderosa herramienta para modelar datos textuales.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0112.png\" width=\"500\" />\n",
    "\n",
    "La imagen muestra una HMM que aprende los tags del POS. En este caso, JJ(adjetive) y NN (noun) son estados ocultos, mientras que \"natural language processing (nlp) ...\" son directamente observables.\n",
    "\n",
    "#### - Conditional Random Fields\n",
    "\n",
    "### 3. basado en Deep Learning\n",
    "\n",
    "#### - Recurrent Neural Networks \n",
    "\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0113.png\" width=\"500\" />\n",
    "\n",
    "#### - Long Short-term memory\n",
    "\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0114.png\" width=\"500\" />\n",
    "\n",
    "#### - Convolutional neural networks\n",
    "\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0115.png\n",
    "\" width=\"500\" />\n",
    "\n",
    "#### - Transformers\n",
    "\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0116.png\n",
    "\" width=\"500\" />\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0117.png\n",
    "\" width=\"500\" />\n",
    "\n",
    "#### - Autoencoders\n",
    "\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0118.png\n",
    "\" width=\"500\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
